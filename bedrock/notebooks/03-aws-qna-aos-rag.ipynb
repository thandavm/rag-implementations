{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7104632-dfce-491a-b3f4-f67cf0b8d0c2",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) using Amazon Bedrock and Amazon OpenSearch\n",
    "In this notebook, we demonstrate a RAG solution that uses Amazon OpenSearch as a vector database (knowledge base) and Amazon Bedrock for generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4ada-a686-43de-bc90-0f4107f95ce1",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Install the required packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae348abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install opensearch-py --quiet\n",
    "!pip3 install requests_aws4auth --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52706ec1-fd47-42d4-af0f-33f0a03f654d",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import the relevant packages and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eea5f6-50e3-4398-80eb-11b680d026b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging \n",
    "import boto3\n",
    "import yaml\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import display, clear_output\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e3b3f-f770-4b90-bc35-12cc0f793604",
   "metadata": {},
   "source": [
    "### Define variables\n",
    "- Define the Bedrock embedding model and the generation model.\n",
    "- Set the region name\n",
    "- Create boto3 client for bedrock\n",
    "- Create Langchain modules for Bedrock embeddings and LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a24c9-b504-45a0-888d-fe507b34402d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BEDROCK_EMBEDDING_MODEL = \"amazon.titan-embed-text-v1\"\n",
    "BEDROCK_GENERATION_MODEL = 'anthropic.claude-v2'\n",
    "REGION_NAME = boto3.session.Session().region_name\n",
    "\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")\n",
    "credentials = boto3.Session().get_credentials()\n",
    "\n",
    "embeddings = BedrockEmbeddings(model_id=BEDROCK_EMBEDDING_MODEL, \n",
    "                               client=boto3_bedrock)\n",
    "generation = Bedrock(model_id=BEDROCK_GENERATION_MODEL,\n",
    "                     client=boto3_bedrock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15fa38a-b08a-4031-93f2-de17a13a359b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Retrieve the following from the parameter store - \n",
    "- Access Key\n",
    "- Secret Access Key\n",
    "- OpenSearch Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31272b-0377-49ff-bcfd-132f63b12027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm_client = boto3.client('ssm')\n",
    "access_key = ssm_client.get_parameter(Name='AccessKey')['Parameter']['Value']\n",
    "secret_key = ssm_client.get_parameter(Name='SecretAccessKey')['Parameter']['Value']\n",
    "host = ssm_client.get_parameter(Name='OpenSearchHost')['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15360977-8631-4a21-a599-b91c91c8c893",
   "metadata": {},
   "source": [
    "### Create a OpenSearch Index\n",
    "\n",
    "Here, we use OpenSearch as a Vector Store. The first step is to create an Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a6e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = 'aoss'\n",
    "\n",
    "INDEX_NAME = 'sm_docs_' + ''.join(random.choices(string.ascii_lowercase, k=8))\n",
    "VECTOR_FIELD = 'vectors'\n",
    "\n",
    "awsauth = AWS4Auth(access_key, secret_key,\n",
    "                   REGION_NAME, service)# session_token=credentials.token)\n",
    "\n",
    "# Create the OpenSearch client\n",
    "aoss_client = OpenSearch(\n",
    "        hosts=[{'host': host, 'port': 443}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        ssl_assert_hostname = False,\n",
    "        ssl_show_warn = False,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=300\n",
    "    )\n",
    "\n",
    "##Delete the index if exists\n",
    "#response = aoss_client.indices.delete(\n",
    "#    index = INDEX_NAME\n",
    "#)\n",
    "\n",
    "#Create the index\n",
    "aoss_client.indices.create(INDEX_NAME, \n",
    "    body={\n",
    "        \"settings\":{\n",
    "            \"index.knn\": True\n",
    "        },\n",
    "        \"mappings\":{\n",
    "            \"properties\": {\n",
    "                \"vectors\": {\n",
    "                    \"type\": \"knn_vector\", \n",
    "                    \"dimension\": 1536 # dimension of the embedding vector\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2eb0d",
   "metadata": {},
   "source": [
    "### Load the documents for Indexing\n",
    "\n",
    "This step performs the following actions:\n",
    "1. Splits the document into chunks\n",
    "2. Creates a numerical vector representation of each chunk using Amazon Bedrock Titan Embeddings model\n",
    "3. Creates an index using the chunks and the corresponding embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17086abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"../data/Amazon_SageMaker_FAQs.csv\") # --- > 219 docs with 400 chars, each row consists in a question column and an answer column\n",
    "documents_aws = loader.load() #\n",
    "print(f\"Number of documents={len(documents_aws)}\")\n",
    "\n",
    "docs = CharacterTextSplitter(chunk_size=2000, chunk_overlap=400, separator=\",\").split_documents(documents_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in docs:\n",
    "    # The text data of each chunk\n",
    "    exampleContent = i.page_content\n",
    "    # Generating the embeddings for each chunk of text data\n",
    "    exampleInput = json.dumps({\"inputText\": exampleContent})\n",
    "    exampleVectors = embeddings.embed_query(exampleInput)\n",
    "\n",
    "    # setting the text data as the text variable, and generated vector to a vector variable\n",
    "    text = exampleContent\n",
    "    vectors = exampleVectors\n",
    "    \n",
    "    indexDocument = {VECTOR_FIELD: vectors,'text': text}\n",
    "   \n",
    "    response = aoss_client.index(\n",
    "        index=INDEX_NAME,\n",
    "        body=indexDocument,\n",
    "        refresh=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1928d",
   "metadata": {},
   "source": [
    "### Query OpenSearch\n",
    "\n",
    "Define a function that queries OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_docs(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Convert the query into embedding and then find similar documents from AOSS\n",
    "    \"\"\"\n",
    "\n",
    "    # embedding\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "    # query to lookup OpenSearch kNN vector. Can add any metadata fields based filtering\n",
    "    # here as part of this query.\n",
    "    query_qna = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "            \"vectors\": {\n",
    "                \"vector\": query_embedding,\n",
    "                \"k\": k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # OpenSearch API call\n",
    "    relevant_documents = aoss_client.search(\n",
    "        body = query_qna,\n",
    "        index = INDEX_NAME\n",
    "    )\n",
    "    return relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_for_query(q: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a context out of the similar docs retrieved from the vector database\n",
    "    by concatenating the text from the similar documents.\n",
    "    \"\"\"\n",
    "    print(f\"query -> {q}\")\n",
    "    aoss_response = query_docs(q)\n",
    "    context = \"\"\n",
    "    for r in aoss_response['hits']['hits']:\n",
    "        s = r['_source']\n",
    "        context += f\"{s['text']}\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec3bc3-585d-418e-bb49-43c7f4bad54b",
   "metadata": {},
   "source": [
    "Create a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How can I check for imbalances in my model?'\n",
    "\n",
    "context = create_context_for_query(query)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "\n",
    "Human: Answer the question asked in the <question> tag based only on the context provided in <context> tags. Do not include any preamble in your answer.\n",
    "<context>\n",
    "{}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{}\n",
    "</question>\n",
    "\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PROMPT_TEMPLATE.format(context, query)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d786db-beda-4859-811b-ee827e604822",
   "metadata": {},
   "source": [
    "### Prompt the LLM (Bedrock - Claudev2) to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113187c-17a2-49a7-9443-e28e27934bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = generation(prompt)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
