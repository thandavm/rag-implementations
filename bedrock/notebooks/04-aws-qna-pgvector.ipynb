{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "1.  Create a RDS Postgres DB\n",
    "2.  Login to the Database\n",
    "3.  Create a Vector Extension for the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a pointer to Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "BEDROCK_EMBEDDING_MODEL = \"amazon.titan-embed-text-v1\" \n",
    "BEDROCK_GENERATION_MODEL = 'anthropic.claude-v2'\n",
    "REGION_NAME = boto3.session.Session().region_name\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the dataset for the Knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://jumpstart-cache-prod-us-east-2/training-datasets/Amazon_SageMaker_FAQs/Amazon_SageMaker_FAQs.csv to ../data/Amazon_SageMaker_FAQs.csv\n"
     ]
    }
   ],
   "source": [
    "s3_path = \"s3://jumpstart-cache-prod-us-east-2/training-datasets/Amazon_SageMaker_FAQs/Amazon_SageMaker_FAQs.csv\"\n",
    "!aws s3 cp $s3_path ../data/Amazon_SageMaker_FAQs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Vector Embeddings for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents=153\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "br_embeddings = BedrockEmbeddings(model_id=BEDROCK_EMBEDDING_MODEL, client=boto3_bedrock)\n",
    "\n",
    "loader = CSVLoader(\"../data/Amazon_SageMaker_FAQs.csv\") # --- > 219 docs with 400 chars, each row consists of a question column and an answer column\n",
    "documents_aws = loader.load()\n",
    "print(f\"Number of documents={len(documents_aws)}\")\n",
    "\n",
    "docs = CharacterTextSplitter(chunk_size=2000, chunk_overlap=400, separator=\",\").split_documents(documents_aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Collection in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.pgvector import PGVector\n",
    "import psycopg2\n",
    "\n",
    "dbhost = ''\n",
    "db = ''\n",
    "dbuser = ''\n",
    "dbpass = ''\n",
    "dbport = '5432'\n",
    "\n",
    "connection_string = PGVector.connection_string_from_db_params(                                                  \n",
    "    driver = 'psycopg2',\n",
    "    user = dbuser,                                      \n",
    "    password = dbpass,                                  \n",
    "    host = dbhost,                                            \n",
    "    port = dbport,                                          \n",
    "    database = db                                       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"sagemaker_faqs\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "     embedding=br_embeddings,\n",
    "     documents=docs,\n",
    "     collection_name=collection_name,\n",
    "     connection_string=connection_string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query from the Pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"How can I check for imbalances in my model?\"\n",
    "\n",
    "def create_context_for_query(query):\n",
    "    context = \"\"\n",
    "    docs_with_score = db.similarity_search_with_score(query)\n",
    "    for doc, score in docs_with_score:\n",
    "        context += doc.page_content + \"\\n\"\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: Answer the question asked in the <question> tag based only on the context provided in <context> tags. Do not include any preamble in your answer.\n",
      "<context>\n",
      "﻿What is Amazon SageMaker?: How can I check for imbalances in my model?\n",
      "Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Amazon SageMaker Clarify helps improve model transparency by detecting statistical bias across the entire ML workflow. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time, and also includes tools to help explain ML models and their predictions. Findings can be shared through explainability reports.\n",
      "﻿What is Amazon SageMaker?: How can I check for imbalances in my model?\n",
      "Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Amazon SageMaker Clarify helps improve model transparency by detecting statistical bias across the entire ML workflow. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time, and also includes tools to help explain ML models and their predictions. Findings can be shared through explainability reports.\n",
      "﻿What is Amazon SageMaker?: What kind of bias does Amazon SageMaker Clarify detect?\n",
      "Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You need to choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\n",
      "﻿What is Amazon SageMaker?: What kind of bias does Amazon SageMaker Clarify detect?\n",
      "Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Measuring bias in ML models is a first step to mitigating bias. Bias may be measured before training and after training, as well as for inference for a deployed model. Each measure of bias corresponds to a different notion of fairness. Even considering simple notions of fairness leads to many different measures applicable in various contexts. You need to choose bias notions and metrics that are valid for the application and the situation under investigation. SageMaker currently supports the computation of different bias metrics for training data (as part of SageMaker data preparation), for the trained model (as part of Amazon SageMaker Experiments), and for inference for a deployed model (as part of Amazon SageMaker Model Monitor). For example, before training, we provide metrics for checking whether the training data is representative (that is, whether one group is underrepresented) and whether there are differences in the label distribution across groups. After training or during deployment, metrics can be helpful to measure whether (and by how much) the performance of the model differs across groups. For example, start by comparing the error rates (how likely a model's prediction is to differ from the true label) or break further down into precision (how likely a positive prediction is to be correct) and recall (how likely the model will correctly label a positive example).\n",
      "\n",
      "</context>\n",
      "\n",
      "<question>\n",
      "How can I check for imbalances in my model?\n",
      "</question>\n",
      "\n",
      "\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "query = 'How can I check for imbalances in my model?'\n",
    "\n",
    "context = create_context_for_query(query)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "\n",
    "Human: Answer the question asked in the <question> tag based only on the context provided in <context> tags. Do not include any preamble in your answer.\n",
    "<context>\n",
    "{}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{}\n",
    "</question>\n",
    "\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PROMPT_TEMPLATE.format(context, query)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '95403d4e-44e2-4930-a19f-55469877a359', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 09 Nov 2023 22:40:18 GMT', 'content-type': 'application/json', 'content-length': '418', 'connection': 'keep-alive', 'x-amzn-requestid': '95403d4e-44e2-4930-a19f-55469877a359'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0x10f53dcf0>}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "body = json.dumps({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"max_tokens_to_sample\":4096,\n",
    "                    \"temperature\":0.5,\n",
    "                    \"top_k\":250,\n",
    "                    \"top_p\":0.5,\n",
    "                    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "                  }) \n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=BEDROCK_GENERATION_MODEL, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Amazon SageMaker Clarify helps improve model transparency by detecting statistical bias across the entire ML workflow. SageMaker Clarify checks for imbalances during data preparation, after training, and ongoing over time, and also includes tools to help explain ML models and their predictions. Findings can be shared through explainability reports.\n"
     ]
    }
   ],
   "source": [
    "print(response_body.get('completion'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
